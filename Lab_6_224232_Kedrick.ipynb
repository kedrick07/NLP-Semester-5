{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kedrick07/NLP-Semester-5/blob/main/Lab_6_224232_Kedrick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 6: Naive Bayes Text Classification**\n",
        "**Course:** SKM3206 â€“ Natural Language Processing  \n",
        "**Lecturer:** Assoc. Prof. Dr. Azreen Azman / Dr. Nurul Amelina Nasharuddin  \n",
        "**Due date:** 21 January 2026 (Wednesday)\n",
        "\n",
        "> âš ï¸ **Instructions:**  \n",
        "> 1. Go to *File â†’ Save a copy in Drive* before editing.  \n",
        "> 2. Rename your notebook as `Lab_LabNo_StudentID_Name.ipynb`.\n",
        "> 3. Read the examples carefully before attempting the exercises.\n",
        "> 4. Complete all the tasks in the code cells provided.  \n",
        "> 5. Submit your Colab link (e.g. http://colab.research.google.com/drive/....) as a submission in the PutraBlast.  "
      ],
      "metadata": {
        "id": "mdt6bVJLL_uZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Classification Using Naive Bayes**\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Define the Dataset**\n",
        "In this task, you are using a small dataset of messages that need to be classified as either \"Spam\" or \"Not Spam.\" The dataset consists of two lists:\n",
        "- **`messages`**: A list of short text messages that could be spam or not. For example, `\"Free entry in a competition\"` is a spam message, while `\"Lunch at 1 pm?\"` is a normal message.\n",
        "- **`labels`**: A list of labels that classify each message. The labels are either `'Spam'` or `'Not Spam'`. These labels represent the target outcome the model will learn to predict.\n",
        "\n",
        "For example, the first message in the list is `\"Free entry in a competition\"`, which is labeled as `'Spam'`. The second message `\"Call me tomorrow\"` is labeled as `'Not Spam'`.\n",
        "\n"
      ],
      "metadata": {
        "id": "VUJ9IjjfjLbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "messages = [\n",
        "    \"Free entry in a competition\", \"Call me tomorrow\",\n",
        "    \"Win cash prizes now\", \"Lunch at 1 pm?\",\n",
        "    \"Claim your free vacation now\", \"Can we reschedule our meeting?\",\n",
        "    \"Hurry, offer ends soon!\"\n",
        "]\n",
        "\n",
        "labels = ['Spam', 'Not Spam', 'Spam', 'Not Spam', 'Spam', 'Not Spam', 'Spam']\n"
      ],
      "metadata": {
        "id": "7p67EteDmac5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **2. Vectorizing the Text Data**\n",
        "### **What is Vectorization?**\n",
        "Machine learning models cannot directly work with text. We need to convert the text into numerical data. To do this, we use a technique called **vectorization**. Specifically, we use the **Bag-of-Words** model, which converts text into a matrix of word counts.\n",
        "\n",
        "Hereâ€™s the process:\n",
        "- Each unique word in the dataset is treated as a feature.\n",
        "- The number of times each word appears in a message is counted.\n",
        "  \n",
        "For example:\n",
        "- If the words in the messages are **`[\"Free\", \"entry\", \"competition\", \"Call\", \"tomorrow\", \"Win\", \"cash\", \"prizes\", \"Lunch\", \"pm\"]`**, we create a feature for each of these words.\n",
        "- The vectorizer counts how many times each word appears in each message and represents this as a list of numbers. For instance, the message `\"Free entry in a competition\"` would be represented as a vector like `[1, 1, 1, 0, 0, 0, 0, 0, 0, 0]`, where `1` indicates the presence of a word and `0` means the word is not in the message.\n",
        "\n",
        "This transformation results in a **bag-of-words matrix** that represents the messages numerically, making them ready for machine learning algorithms to process.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hKR9eHt8mF-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(messages)"
      ],
      "metadata": {
        "id": "PBlcQryemcYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **3. Encoding Labels**\n",
        "In the dataset, the labels are either `'Spam'` or `'Not Spam'`. Since machine learning algorithms work with numerical data, we need to encode these labels into numbers:\n",
        "- **`'Spam'`** is encoded as `1`\n",
        "- **`'Not Spam'`** is encoded as `0`\n",
        "\n",
        "For instance:\n",
        "- The label `'Spam'` would become `1`.\n",
        "- The label `'Not Spam'` would become `0`.\n",
        "\n",
        "This transformation is necessary because the model works with numbers, not text.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VALOJdWsmJ2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = [1 if label == 'Spam' else 0 for label in labels]"
      ],
      "metadata": {
        "id": "coRQoimCmnpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Splitting the Dataset**\n",
        "The dataset is divided into two parts:\n",
        "1. **Training Set**: This is the portion of the data used to train the model. The model will learn to recognize patterns in this data.\n",
        "2. **Test Set**: This portion is used to evaluate the performance of the model. It tests how well the model can generalize to unseen data.\n",
        "\n",
        "For instance:\n",
        "- **Training Set**: The model will learn from messages like `\"Free entry in a competition\"`, `\"Win cash prizes now\"`, and `\"Lunch at 1 pm?\"`.\n",
        "- **Test Set**: The model will test its predictions on new messages, like `\"Call me tomorrow\"`.\n",
        "\n",
        "The dataset is typically split into an 80/20 or 70/30 ratio (training to test), where the majority of the data is used for training.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rjODvDtYmObe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "lZ6_B9Z6msew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Training the Model**\n",
        "Now that the data is ready, we use the **Naive Bayes** algorithm to train the model. The Naive Bayes classifier is a simple probabilistic model based on Bayes' Theorem. It works well for text classification problems because it assumes that the presence of each word is independent of the others.\n",
        "\n",
        "### **Training Process:**\n",
        "- The model is provided with the training data (messages and their corresponding labels).\n",
        "- The Naive Bayes classifier learns the relationship between the words and the labels. For example, it will learn that words like `\"Free\"`, `\"Win\"`, and `\"Prizes\"` are often associated with spam messages.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PSapPUr0mROZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "yqy45PaXmvKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Predicting on Test Data**\n",
        "Once the model has been trained, we can use it to make predictions on new, unseen data. The trained model is tested on the test set (messages it has not seen before) to predict whether each message is spam or not.\n",
        "\n",
        "For example:\n",
        "- The model might predict that the message `\"Call me tomorrow\"` is **Not Spam** based on the learned patterns.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P8ipxgV8mT3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = nb_classifier.predict(X_test)\n"
      ],
      "metadata": {
        "id": "XCb36J9Nmxqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Evaluating the Model**\n",
        "To evaluate the performance of the model, we use two key metrics:\n",
        "1. **Confusion Matrix**: This is a table that helps us understand how well the model is performing. It shows:\n",
        "   - **True Positives (TP)**: Correctly predicted spam messages.\n",
        "   - **True Negatives (TN)**: Correctly predicted non-spam messages.\n",
        "   - **False Positives (FP)**: Non-spam messages incorrectly predicted as spam.\n",
        "   - **False Negatives (FN)**: Spam messages incorrectly predicted as non-spam.\n",
        "\n",
        "   For example: [[1 0] # True Negatives [0 1]] # True Positives\n",
        "\n",
        "2. **Accuracy**: This is the proportion of correct predictions out of all predictions. It is calculated by dividing the number of correct predictions by the total number of predictions. For example, if the model made 4 predictions and got 3 correct, the accuracy would be 75%.\n",
        "\n",
        "These metrics help us understand how well the model is working and where it might need improvement.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZgYnaNLDmV7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "kmppeO2amz5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task for Students**\n",
        "\n",
        "### **Question:**\n",
        "Search for a text classification dataset on [Kaggle](https://www.kaggle.com/datasets/team-ai/spam-text-message-classification). Choose a dataset that involves classifying text into categories (e.g., spam vs. non-spam, sentiment analysis, etc.).\n",
        "\n",
        "1. Download the dataset and load it into your Python environment.\n",
        "2. Preprocess the dataset by:\n",
        "   - Tokenizing and vectorizing the text data (e.g., using `CountVectorizer` or `TfidfVectorizer`).\n",
        "   - Encoding the labels into numerical values if necessary (e.g., converting 'spam' to 1 and 'not spam' to 0).\n",
        "3. Split the dataset into training and testing sets.\n",
        "4. Use the **Naive Bayes** algorithm (e.g., `MultinomialNB`) to train the model on the training data.\n",
        "5. Make predictions on the test data and evaluate the model by:\n",
        "   - Displaying the confusion matrix.\n",
        "   - Calculating the accuracy score.\n",
        "6. Experiment with different preprocessing techniques or datasets and compare the results.\n"
      ],
      "metadata": {
        "id": "g9lec2qTmXsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ðŸ“¤ **Submission Reminder:**  \n",
        "\n",
        "Submit the following via PutraBlast:\n",
        "\n",
        "- The link to your Colab notebook (as *Viewer link*). Ensure the file name is `LabNo_StudentID_Name.ipynb`.\n",
        "- Link to Kaggle dataset, the confusion matrices and accuracy scores.\n"
      ],
      "metadata": {
        "id": "wzoDuxj0rwIT"
      }
    }
  ]
}