{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kedrick07/NLP-Semester-5/blob/main/Lab_3_224232_Kedrick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 3: Part of Speech Tagging**\n",
        "**Course:** SKM3206 ‚Äì Natural Language Processing  \n",
        "**Lecturer:** Assoc. Prof. Dr. Azreen Azman / Dr. Nurul Amelina Nasharuddin  \n",
        "**Due date:** 9 November 2025 (Sunday)\n",
        "\n",
        "> ‚ö†Ô∏è **Instructions:**  \n",
        "> 1. Go to *File ‚Üí Save a copy in Drive* before editing.  \n",
        "> 2. Rename your notebook as `Lab_LabNo_StudentID_Name.ipynb`.\n",
        "> 3. Read the examples carefully before attempting the exercises.\n",
        "> 4. Complete all the tasks in the code cells provided.  \n",
        "> 5. Submit your Colab link (e.g. http://colab.research.google.com/drive/....) as a submission in the PutraBlast.  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vCExb-DsYsOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üß† Warm-up Examples**"
      ],
      "metadata": {
        "id": "sqas9Ip0_-Li"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Example 1: Reading a Text File**"
      ],
      "metadata": {
        "id": "uT135IIYied0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload and read a text file\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "filename = list(uploaded.keys())[0]\n",
        "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(text[:500])  # Show the first 500 characters\n"
      ],
      "metadata": {
        "id": "RbKFInaz70Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discussion: What does this code do? Why do we use \"utf-8\" encoding?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "nM94F-l6hPvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Example 2: Sentence and Word Tokenisation**"
      ],
      "metadata": {
        "id": "-yZKjbNbhe5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "print(\"Number of sentences:\", len(sentences))\n",
        "print(\"First sentence:\", sentences[0])\n",
        "\n",
        "tokens = nltk.word_tokenize(sentences[0])\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "68SlfK3jh0VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discussion: What is the difference between `sent_tokenize` and `word_tokenize`?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "S3eR_W3DiDcn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Example 3: POS Tagging with Default (Penn Treebank) Tagset**\n",
        "\n",
        "This is the Penn Treebank tagset ‚Äî more detailed, but harder to memorise."
      ],
      "metadata": {
        "id": "w6Df68Iuial0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "print(tagged)"
      ],
      "metadata": {
        "id": "-vmpckX1juwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discussion: Notice tags like NN, VBZ, DT, JJ.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "_q4uaDXfjyk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Example 4: POS Tagging with the Universal Tagset**"
      ],
      "metadata": {
        "id": "MqdZfV8kj_sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_universal = nltk.pos_tag(tokens, tagset='universal')\n",
        "print(tagged_universal)"
      ],
      "metadata": {
        "id": "92PVpEtNkLpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discussion: Universal tagset uses simpler tags (e.g. NOUN, VERB, DET, ADJ, ADV).\n",
        "Refer to https://universaldependencies.org/u/pos/\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CMFaPP8EkVQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Example 5: Counting POS Frequencies**"
      ],
      "metadata": {
        "id": "soorIoECkaeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "pos_counts = Counter(tag for (word, tag) in tagged_universal)\n",
        "print(pos_counts)"
      ],
      "metadata": {
        "id": "7t3t2p_SkfWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discussion: How could frequency analysis help in understanding the nature of the text (e.g. news vs fiction)?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vtgR-hqskgRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**‚úçÔ∏è Exercises**\n"
      ],
      "metadata": {
        "id": "RyffPUmfk1Ua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1: File Reading and Sentence Counting**\n",
        "\n",
        "Upload your own short text file (about 3‚Äì5 sentences). Write code to:\n",
        "*  read the file\n",
        "*  count and print how many sentences are in the file\n",
        "*  print only the second sentence"
      ],
      "metadata": {
        "id": "YJvIyVsqlFTh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kp0UZ4jclxim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2: POS Tagging Practice**\n",
        "\n",
        "Use the sentence below.\n",
        "Tokenize it and print the POS tags using the universal tagset."
      ],
      "metadata": {
        "id": "1PEr5Trfl0Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Artificial intelligence transforms modern education.\"\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "DH1ps1khmEgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 3: Count Only NOUNs and VERBs**\n",
        "\n",
        "Modify your code to count how many tokens are tagged as NOUN or VERB."
      ],
      "metadata": {
        "id": "Ej5wabnUmKBo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fpVR0swVmXOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üßÆ **Lab Assignment**\n",
        "Complete the following tasks and ensure your answers run without error.\n"
      ],
      "metadata": {
        "id": "cFGaPinHQQ53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Step 1: Manual Tagging**\n",
        "\n",
        "Go to an English newspaper website (e.g. The Star, New Straits Times).\n",
        "\n",
        "Copy one complete article into a `.txt` file.\n",
        "\n",
        "Select the first sentence and manually tag each word using the UD POS tags (ADJ, NOUN, VERB, etc.). Reference: https://universaldependencies.org/u/pos/\n",
        "\n",
        "Which words were difficult to tag? Why?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "z4XVzjcUiWmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_correction(input_word, dictionary):\n",
        "  #Write your code here"
      ],
      "metadata": {
        "id": "ZcVriQMoMY1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "###**Step 2: Automatic Tagging with NLTK**\n",
        "\n",
        "Using what you learned in above sections, write Python code to:\n",
        "\n",
        "1. Read the article text file from Step 1.\n",
        "2. Tokenize the text.\n",
        "3. Apply POS tagging using NLTK with the Universal tagset.\n",
        "4. Save all tagged tokens into an output text file (`tagged_output.txt`).\n",
        "5. Calculate and print the frequency of each POS tag. Use `Counter()` to count POS tags.\n",
        "\n",
        "Make sure you download required NLTK resources (`punkt`, `averaged_perceptron_tagger`)."
      ],
      "metadata": {
        "id": "IrdkjD0yjCNb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2yDO-MiYkpho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üì§ **Submission Reminder:**  \n",
        "\n",
        "Submit the following via PutraBlast:\n",
        "\n",
        "- The link to your Colab notebook (as *Viewer link*). Ensure the file name is `LabNo_StudentID_Name.ipynb`.\n",
        "- The article text file (`.txt`)\n",
        "- The tagged output file (`tagged_output.txt`)\n",
        "- Screenshot of your manual tagging  \n",
        "---\n"
      ],
      "metadata": {
        "id": "_xIrY2pJe_kT"
      }
    }
  ]
}